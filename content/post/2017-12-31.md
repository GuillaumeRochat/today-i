+++
date = "2017-12-31T10:04:24+00:00"
draft = true
title = "We're Ironic"

+++
... read [To Serve Man, with Software by Coding Horror](https://blog.codinghorror.com/to-serve-man-with-software/). It brought back a subject I've had in my mind for a while now: how we, as a software developer, are ironic. Let me illustrate what I mean by that.

Whenever we think about a great future in software, we come up with crazy idea about how great things could be. We could have camera everywhere that can do face recognition on everyone and whenever a criminal is nearby, it's going to send an alter to the nearest police so he can be arrested. That's great right? But wait, it's dangerous. What if the face recognition is a false positive and he's shot on sight? What is someone uses those same cameras for something else? Could it be used wrongfully? We all know the answer. We know what we think about can be used wrongfully, and we know that it would be amazing in an utopia, but such a world does not exist. What can go wrong will go wrong, yet we still develop software that can be wrongfully used, we ask people to trust us, and to trust it will not be used the wrong way.

It's amazing that I can have a Google Home device and just ask it to do things at home. But it also means that there is sometime constantly listening to what I'm doing at home, self updating. I understand how it could be used for evil, yet I still use it and try to ignore the fact, wishing it won't happen.

Many advances in technologies require information, or access, that, if used wrongfully, could have dire consequences. We're ironic because we dream of a world where we have all those great technologies helping us make our lives better, but at the same time dread this world where everything could become a source of threat. We dream of a highly technological world and wish to go back into the wood to hide ourselves from the very technology we built.

It is 