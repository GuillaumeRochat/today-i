+++
date = "2017-12-31T10:04:24+00:00"
draft = true
title = "We're Ironic"

+++
... read [To Serve Man, with Software by Coding Horror](https://blog.codinghorror.com/to-serve-man-with-software/). It brought back a subject I've had in my mind for a while now: how we, as software developers, are sometimes ironic. Let me illustrate what I mean by that.

Whenever we think about a great future in software, we come up with crazy ideas about how great things could be. For instance, we could have cameras everywhere to do face recognition on everyone and whenever a criminal would be nearby, it's would send an alert to the nearest police station so the criminal could be arrested. That's great right? But wait, isn't it dangerous? What if the face recognition is a false positive and he's shot on sight? What is someone uses those same cameras for something else? What if the criminal database is corrupted or not secure enough? Could it be used wrongfully? We all know the answer. We know what we dream about can be used wrongfully, and we know that it would be amazing in an utopia, but such a world does not exist. What can go wrong will go wrong, yet we still develop software that can be wrongfully used, we ask people to trust us, and to trust it will not be used the wrong way and we try to add securities just enough to reassure ourselves.

It's amazing that I can have a Google Home device and just ask it to do things at home. But it also means that there is something constantly listening what I'm doing at home. I understand how it could be used for evil, yet I still use it and try to ignore the fact, wishing it won't happen.

Many advances in technologies require information, or access, that, if used wrongfully, could have dire consequences. We're ironic because we dream of a world where we have all those great technologies helping us make our lives better, but at the same time dread this world where everything could become a source of threat. We dream of a highly technological world and wish to go back into the wood to hide ourselves from the very technology we built.

It is a constant struggle in my brain, about whether I should follow X or Y. I decided to stop using Google and Chrome, so I'm using DuckDuckGo and Firefox now, with a lot of privacy settings, yet I can't get rid of Inbox, I use Chromecast, and I'm thinking about a Google Home. I know it violates some of the principles I try to follow, but I'm not sure whether it matters that I follow them or not. I'm still undecided and I keep edging on one side or the other.

We're also ironic in another way: we try to solve people's problems with software while also being the group being highly depicted as lacking in people skills. How can we solve these people's problems when we can't understand them ourselves? I was hearing some critics about Tinder on the radio this morning, about how it wasn't actually helping in finding anyone worth knowing. When they created that application, did they even consider the personalities of the clients? How they would use it? To what mean? What type of people would use it and what type wouldn't? Maybe they would have realized it would mostly be used wrongfully and might not have done it, or maybe they wouldn't have cared.

To come back to Coding Horror's post, I'm wondering if technology, past a certain point is worth it. Maybe it isn't. Maybe I'm just in the same place than critics of steam, writing, telegram or phone were in the past, criticizing the new development because it is an unknown, and being worried for nothing. In any case, I'm still not sure on which leg to stand on, but my Optimistic Nihilism point of view tells me that it won't matter in the end.