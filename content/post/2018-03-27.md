+++
date = "2018-03-27T18:58:01+00:00"
draft = true
title = "NodeJS Memory Leak"

+++
... spent a good part of the day debugging a memory leak in NodeJS. For those who wonder how there can be memory leaks in garbage collected languages, it's just the other kind of memory leaks. In languages such as C, a memory leak often comes from a no longer referenced pointer that never got released and you can't do anything about it. Those are removed by garbage collectors. But if you keep a reference to an object you no longer need, you still get a memory leak, because the garbage collector can't take it, you're still using it. That's the kind of memory leak that happens when you endlessly appends to an array, or you do circular chains of promises.

In order to track the memory leak, I used 2 tools. First, I monitored the process with Glances to confirm that there was a leak before going further. Since I can see the ram usage of every process even those in containers with Glances, I was able to see the memory slowly climb. The issue with that method is it takes a while to confirm the leak. That's due to the fact that NodeJS is constantly doing optimizations of the application and that optimization makes the ram fluctuate. Also, the application I was debugging goes through a big spike of ram before lowering near the end of the task, which takes a couple of minutes. The amount it goes up by is unpredictable, so I couldn't calculate it very well. But slowly, the lowest number would be higher than before, the higher number would be even higher, etc.

Once I was sure there was a memory leak, I searched the code to see the place where it could be. Fortunately, there wasn't a lot of code to check. The process starts, calls a queue manager, and then the queue manager starts tasks. Between each tasks, the ram usage would slowly climb, so the leak was in anything that the queue manager was doing. To know exactly, I had to do heapdump. There are two ways to do that.

The first method is to add the --inspect flag to the node command that starts the process. What it does is it opens up a link to the chrome devtools and allows monitoring the process through that. Then,  right in the chrome devtools, you can take snapshots of the memory usage. The upside is that it is very simple and doesn't require any other dependency. The downside is that it's not precise enough in terms of snapshots. It's whenever you start the snapshot, but to diagnose the issue, you have to compare different snapshots to see what's the difference between the two. In the middle of a task, there's usually a lot of differences. It creates a lot of noise in the search for the leak.

The second method requires the heapdump package. You simply add that package to your project, and tell it when to take the snapshot and save it to a file. It's really simple, just two lines. The thing is to know exactly when to take the snapshot. In my case, as it's a queue manager and I wasn't running multiple tasks at once, taking a snapshot right before a task starts was the time when. It would write to file at the lowest point of memory usage. Once you got a couple of snapshots taken, you can then load them in the chrome devtools. They actually are the same snapshot than those taken through the chrome devtools, but that you keep on file. Load them all, and then compare. The downside of this method is just the additional package to temporarily add to your project. The upside is you get the dump at exactly the same point in the process.

With that second method, I was able to see a chain of rejected promise pilling up in a mysql library used by Sequelize. Turns out we were using a version a little too old and the promise weren't handled well enough in those early versions. Once I had the right tools, it only took me a few hours to run everything and see where the leak was. It also gave me more confidence in the rest of the application, since only one thing was growing in size in the heap.